{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libaries\n",
    "import scrapy\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libaries\n",
    "#used selenium and chrome to automate a web browser to click through a database on an aspx webpage since it couldn't be scraped by normal means\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use but make sure you have the right link\n",
    "#open window in chrome\n",
    "#make sure you have correct version for chrome webdriver\n",
    "\n",
    "driver = webdriver.Chrome('C:\\\\Users\\\\akomandu\\\\Python_Stuff\\\\chromedriver.exe')\n",
    "driver.get('https://sunproductsmsdsbrand.thewercs.com/private/results.aspx?__VIEWSTATEGENERATOR=D6323F43&subformat=d__AGHS&language=d__EN')\n",
    "driver.maximize_window()\n",
    "\n",
    "#start a while loop that breaks once the end of the database has been reached\n",
    "#on each page, click links that link to a downloadable pdf\n",
    "#this will append the all the download links on a page to one item in the list \"links\"\n",
    "while True:\n",
    "#open page, click next to get to next page once all the links have been downloaded\n",
    "    try:\n",
    "        page = driver.page_source\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        if soup.find_all('a', attrs={'href':True})[13:] not in links:\n",
    "            links.append(soup.find_all('a', attrs={'href':True})[13:])\n",
    "        time.sleep(5)\n",
    "        element = driver.find_element_by_link_text(\"Next\")\n",
    "        element.click()\n",
    "        \n",
    "#since there's no next button, we've reached the last page of the database. Now we can break the loop\n",
    "    except:\n",
    "        page=driver.page_source\n",
    "        soup=BeautifulSoup(page, 'html.parser')\n",
    "        if soup.find_all('a', attrs={'href':True})[13:] not in links:\n",
    "            links.append(soup.find_all('a', attrs={'href':True})[13:])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separate each page's download links into individual items in a list that we can then append\n",
    "all_links=[]\n",
    "for i in range(len(links)):\n",
    "    for p in range(len(links[i])):\n",
    "        all_links.append(links[i][p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reconstruct each link into a downloadable url where the pdf can be retrieved from\n",
    "#replace INDS/AGHS/SPNA with specific document type when appending\n",
    "download_links= []\n",
    "for p in range(len(all_links)):\n",
    "    try:\n",
    "        okay = all_links[p].attrs['href'].split('~~')\n",
    "        yes = okay[0]\n",
    "        prd = yes.split(',')[-1][1:]\n",
    "        wow = okay[5]\n",
    "        hooray = wow.split(' ')\n",
    "        good = okay[6].replace(' ', '%20')\n",
    "        download_links.append('https://sunproductsmsdsbrand.thewercs.com/private/document.aspx?prd=' + prd + '~~PDF~~MTR~~AGHS~~EN~~' + hooray[0] + '%20' + hooray[1].replace(\":\", \"%3A\") + '~~' + good)\n",
    "    except:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download pdf's to local directory\n",
    "for i in range(len(download_links)):\n",
    "    urlretrieve(download_links[i], filename=\"Sun_OSHA_GHS_\" + str(i) + '.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
